{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://docs.langchain.com/oss/python/langgraph/streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(\"/Users/paddy/Documents/Github/Dump-Truck/langchain-ac/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatAnthropic(model=\"MiniMax-M2.1\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State)-> Literal [\"summarize_conversation\",END]:\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://docs.langchain.com/oss/python/langgraph/streaming#supported-stream-modes).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://docs.langchain.com/oss/python/langgraph/streaming#stream-graph-state) for graph state.\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content=[{'signature': '32d63d87e695b37b0c99f6fd801ad826390e8a84f2a98dd1300ba079ec9a0483', 'thinking': 'The user has introduced themselves as Paddy in a very casual, friendly way. This is a simple greeting and introduction, so I should respond in a warm, friendly manner and introduce myself in return. The conversation is just starting, so I should be welcoming and open to helping them.', 'type': 'thinking'}, {'text': \"Hi Paddy! ðŸ‘‹ Nice to meet you! \\n\\nI'm MiniMax-M2.1, an AI assistant built by MiniMax. I'm here to help you with all sorts of tasks - whether that's coding, writing, answering questions, brainstorming ideas, or just having a chat.\\n\\nWhat can I help you with today?\", 'type': 'text'}], additional_kwargs={}, response_metadata={'id': '05a318d3a8d0b4c0dfb5f38233a52f41', 'model': 'MiniMax-M2.1', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': None, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 41, 'input_tokens': 0, 'output_tokens': 126, 'server_tool_use': None, 'service_tier': None}, 'base_resp': {'status_code': 0, 'status_msg': ''}, 'model_name': 'MiniMax-M2.1', 'model_provider': 'anthropic'}, id='lc_run--019b6fb9-bdb3-7193-ac4c-31d820cb2c94-0', usage_metadata={'input_tokens': 41, 'output_tokens': 126, 'total_tokens': 167, 'input_token_details': {'cache_read': 41, 'cache_creation': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Paddy\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'signature': '827c4c4e9af7588920e7baebb97e43dfdfb01b873b1f02d6772ab3e03d4e2747', 'thinking': 'The user has said \"hi! I\\'m Paddy\" three times now. This is either:\\n1. A repeated greeting (perhaps testing if I\\'m responsive)\\n2. Accidentally sent the same message multiple times\\n3. Just being friendly and wanting to chat\\n\\nI should respond warmly and conversationally, perhaps gently noting we\\'ve said hi a few times, but in a friendly way. I\\'ll keep it brief and casual, and invite them to share what they\\'d like help with.', 'type': 'thinking'}, {'text': \"Hey Paddy! ðŸ‘‹\\n\\nWe've said hi a few times now - I think we're officially acquainted! ðŸ˜„\\n\\nSo, what's on your mind? Anything I can help you with - whether it's coding, writing, brainstorming, or something else entirely?\", 'type': 'text'}]\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Paddy\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Paddy\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Paddy\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'signature': 'da5e28ef9358d52cf353ff47c21432c412190812b4319bab909d9325ca7c8811', 'thinking': 'The user has introduced themselves as \"Paddy\". This is a simple greeting and introduction. I should respond in a friendly, welcoming manner and introduce myself as well. Since this is just a casual greeting and not a request for any specific task, I\\'ll keep my response brief and friendly.\\n\\nI should note that I need to be accurate about my identity - I am MiniMax-M2.1, built by MiniMax.', 'type': 'thinking'}, {'text': \"Hi Paddy! ðŸ‘‹\\n\\nI'm MiniMax-M2.1, built by MiniMax. Nice to meet you!\\n\\nHow can I help you today?\", 'type': 'text'}]\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Paddy\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://docs.langchain.com/oss/python/langchain/models#advanced-streaming-topics:streaming-events), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the CSK IPL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_name': 'MiniMax-M2.1', 'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=[{'thinking': 'The user', 'type': 'thinking', 'index': 0}], additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=[{'thinking': ' is asking about the CSK IPL team. CSK stands for Chennai Super Kings, which is a franchise cricket team based in Chennai, India. They participate in the', 'type': 'thinking', 'index': 0}], additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=[{'thinking': ' Indian Premier League (IPL), which is a professional Twenty20 cricket league in India.\\n\\nLet me provide information about CSK:\\n\\n1. Full', 'type': 'thinking', 'index': 0}], additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=[{'thinking': ' name: Chennai Super Kings\\n2. Founded: 2008\\n3. Home ground: M. A. Chidambaram Stadium, Chennai\\n4. Owners: Chennai', 'type': 'thinking', 'index': 0}], additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=[{'thinking': ' Super Kings Limited (India Cements)\\n5. Captain: Currently Ruturaj Gaikwad (as of 2024)', 'type': 'thinking', 'index': 0}], additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=[{'thinking': '\\n6. Mascot: Super Kings\\n7. Colors: Yellow and blue\\n\\nTeam achievements:\\n- IPL Champions: 201', 'type': 'thinking', 'index': 0}], additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=[{'thinking': '0, 2011, 2018, 2021, 2023\\n- Runners-up: 2008, 2012, 2013, ', 'type': 'thinking', 'index': 0}], additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=[{'thinking': '2015, 2019\\n\\nThe team is known for:\\n- Consistency in the IPL\\n- Having MS Dhoni as captain for most of their', 'type': 'thinking', 'index': 0}], additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=[{'thinking': ' history until 2024\\n- Strong fan base called \"Super Kings\"\\n- The iconic yellow jersey\\n\\nI should provide', 'type': 'thinking', 'index': 0}], additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=[{'thinking': ' a comprehensive overview of the team in a well-structured format.', 'type': 'thinking', 'index': 0}], additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=[{'signature': '69596d8c98c1ffe5554c9c5401fa21fd8c3a065c88c7cdc095e71c7861688bcc', 'type': 'thinking', 'index': 0}], additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content='# Chennai Super Kings (CSK) - IPL Team Overview\\n\\nThe', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=' **Chennai Super Kings (CSK)** is one of the most successful and popular franchises in the Indian Premier League (IPL), established in 2008', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=\". Based in Chennai, Tamil Nadu, the team represents the city's rich cricketing heritage and passionate fan base.\\n\\n\", additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content='## Team Identity\\n\\n| Aspect | Details |\\n|--------|---------|\\n| **Full Name** | Chennai Super Kings |\\n| **Short Name** | CSK |\\n| **', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content='Founded** | 2008 |\\n| **Home Ground** | M. A. Chidambaram Stadium, Chennai |\\n| **Colors** | Yellow and Blue |\\n| **M', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=\"ascot** | Super Kings |\\n| **Owners** | Chennai Super Kings Limited |\\n\\n## Leadership\\n\\nThe team's most iconic captain has\", additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=\" been **MS Dhoni**, who led CSK from 2008 to 2023, becoming synonymous with the franchise's success and culture.\", additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=' In 2024, **Ruturaj Gaikwad** took over as captain, marking a new era for the team while maintaining the core values', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=\" established under Dhoni's leadership.\\n\\n## Major Achievements\\n\\nCSK's trophy cabinet reflects their dominance\", additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=' in the IPL:\\n\\n- **IPL Champions**: 2010, 2011, 2018, 2021, 2023\\n- **Runners-up**: ', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content='2008, 2012, 2013, 2015, 2019\\n- **Champions League Twenty20**: 2010, 201', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=\"4\\n\\nTheir five IPL titles place them among the most successful teams in the tournament's history, rivaled only by Mumbai Indians.\\n\\n## Signature\", additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=' Characteristics\\n\\nCSK is renowned for several distinctive qualities that set them apart:\\n\\n- **Consistency**: The team has consistently reached the playoffs across', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=' most seasons\\n- **Yellow Army**: Their passionate fan base, dressed in yellow, creates an electric atmosphere\\n', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content='- **Core Stability**: The franchise has maintained a core group of players over the years\\n- **Strategic Acumen**: Under Dh', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=\"oni's leadership, they became famous for calculated risk-taking\\n\\n## Home Ground\\n\\nThe **\", additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=\"M. A. Chidambaram Stadium** (also known as Chepauk Stadium) serves as CSK's home ground. This\", additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=\" historic venue, with a capacity of approximately 50,000, is known for its spin-friendly pitch, which suits CSK's bowling\", additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=\" attack particularly well.\\n\\nThe team's remarkable success, loyal fan base, and iconic yellow jersey have made CS\", additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content='K one of the most beloved franchises in world cricket, transcending regional boundaries and creating a global following known as the', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content=' \"Yellow Brigade.\"', additional_kwargs={}, response_metadata={'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'stop_reason': 'end_turn', 'stop_sequence': None, 'model_provider': 'anthropic'}, id='lc_run--019b6fba-c3f8-71e2-921d-fd37d1720acd', usage_metadata={'input_tokens': 44, 'output_tokens': 794, 'total_tokens': 838, 'input_token_details': {}}, chunk_position='last')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the CSK IPL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|[{'thinking': 'The user', 'type': 'thinking', 'index': 0}]|[{'thinking': ' is asking me to tell them about the CSK IPL team. CSK stands for Chennai Super Kings, which is a professional cricket team that plays in the Indian Premier League (IPL', 'type': 'thinking', 'index': 0}]|[{'thinking': '), which is a professional Twenty20 cricket league in India.\\n\\nLet me provide a comprehensive overview of the team:\\n\\n1. Team overview and', 'type': 'thinking', 'index': 0}]|[{'thinking': ' basic information\\n2. History and establishment\\n3. Performance and achievements\\n4. Captain and key players\\n5.', 'type': 'thinking', 'index': 0}]|[{'thinking': ' Home ground\\n6. Team identity and culture\\n7. Notable facts\\n\\nThis is a general information request, so I', 'type': 'thinking', 'index': 0}]|[{'thinking': ' should write this in an engaging, informative style that covers all the key aspects of the team.', 'type': 'thinking', 'index': 0}]|[{'signature': '631a8ead37f53586a3210cb39260cc58a5ab360ac9af38c87aa030096f4dab37', 'type': 'thinking', 'index': 0}]|# Chennai Super Kings (CSK): A| Complete Overview\n",
      "\n",
      "The **Chennai Super Kings (CSK)** are one of the most successful and iconic franchises in the Indian Premier League (IPL), India's| premier Twenty20 cricket competition. Known for their consistent performances, loyal fanbase, and distinctive yellow jersey, CSK has established itself as a| powerhouse in T20 cricket since the league's inception.\n",
      "\n",
      "## Team Overview\n",
      "\n",
      "The Chennai Super Kings represent the city of Chennai (formerly Madras) in| Tamil Nadu and were founded in 2008 when the IPL was established. The team is owned by Chennai Super Kings Limited, with India's| cricket legend **Mahendra Singh Dhoni** serving as the iconic captain since the team's inception. The Super Kings play their home matches| at the M. A. Chidambaram Stadium in Chennai, one of the oldest and most prestigious cricket grounds in India.\n",
      "\n",
      "## History and Background|\n",
      "\n",
      "CSK's journey in the IPL has been remarkable and at times controversial. The team dominated the early years of the tournament, reaching| the playoffs in their first five seasons and winning the championship twice. After a two-year suspension from the league in |2016 and 2017 due to their involvement in a spot-fixing scandal, CSK made a triumphant return in 2018, winning the title| in their very first season backâ€”an unprecedented achievement in IPL history.\n",
      "\n",
      "## Achievements and Records|\n",
      "\n",
      "The Chennai Super Kings have an impressive trophy cabinet that reflects their consistency and dominance:\n",
      "\n",
      "-| **IPL Championships**: CSK has won the IPL title **5 times** (2010, 2011, 2018, 2021|, and 2023), making them one of the most successful teams in the league's history\n",
      "- **Champions League T20**: They won the Champions League| Twenty20 in 2010 and 2014\n",
      "- **Playoff Record**: CSK holds the record for the most consecutive playoff appearances (11 straight| seasons from 2010 to 2019)\n",
      "- **Win Percentage**: The team boasts one of the highest winning percentages in IPL history,| showcasing their remarkable consistency\n",
      "\n",
      "## Captain and Key Players\n",
      "\n",
      "**Mahendra Singh Dhoni** (MS Dhoni) is the heart and soul of CS|K. His calm leadership, exceptional wicket-keeping skills, and explosive batting have made him one of the most revered| captains in world cricket. Dhoni's ability to finish matches and his tactical acumen have been instrumental in CSK's success over the years.\n",
      "\n",
      "Other| key players who have contributed significantly to CSK's fortunes include:\n",
      "\n",
      "- **Ravindra Jadeja** â€“ An all-rounder known| for his fielding prowess, left-arm spin, and aggressive batting\n",
      "- **Ruturaj Gaikwad** â€“ An elegant| opening batsman who has become a crucial player in recent seasons\n",
      "- **Devon Conway** â€“ The New Zealand batsman who has| added firepower to the top order\n",
      "- **Deepak Chahar** â€“ A swing bowler who provides early| breakthroughs\n",
      "- **Matheesha Pathirana** â€“ The young Sri Lankan pacer known for his slingy action\n",
      "\n",
      "## Home Ground\n",
      "\n",
      "The M|. A. Chidambaram Stadium (Chepauk Stadium) in Chennai serves as CSK's home ground. This historic venue, with a capacity of over| 50,000 spectators, is known for its spin-friendly pitches that suit CSK's bowling attack, particularly their quality spinners. The| stadium has witnessed many memorable CSK victories and is considered a fortress for the team, with CSK having an| exceptional winning record at home.\n",
      "\n",
      "## Team Identity and Culture\n",
      "\n",
      "CSK has cultivated a unique identity and culture that| sets them apart from other IPL franchises:\n",
      "\n",
      "- **\"Whistle Podu\"** â€“ The team's famous chant and anthem|, meaning \"Whistle Podu\" (whistle and go), has become iconic| in the cricket world\n",
      "- **Yellow Jersey** â€“ The team's vibrant yellow color is instantly recognizable and beloved by fans\n",
      "- **Loyal Core|** â€“ CSK is known for retaining core players over multiple seasons, fostering team chemistry and loyalty\n",
      "-| **Massive Fanbase** â€“ The Super Kings have one of the most passionate and loyal fanbases in the IPL, known| as the \"Super Kings Army\"\n",
      "- **Never-say-die Attitude** â€“ The team is famous for staging remarkable| comebacks and winning from difficult situations\n",
      "\n",
      "## Notable Facts\n",
      "\n",
      "- CSK holds the record for the highest run chase in IPL history| (245/3 against Rajasthan Royals in 2018)\n",
      "- The team has the most successful captain| in IPL history in MS Dhoni\n",
      "- CSK was the first team to reach 100 wins in IPL matches\n",
      "- The franchise| is valued at over $1 billion, making it one of the most valuable sports franchises in India\n",
      "- Despite their success, CSK is| known for their balanced approach in the auction, often investing in experienced players who| fit their system\n",
      "\n",
      "The Chennai Super Kings represent the perfect blend of experience, talent, and team spirit,| making them one of the most beloved and successful teams in the history of the Indian Premier League.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the CSK IPL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "**âš ï¸ Notice**\n",
    "\n",
    "Since filming these videos, we've updated Studio so that it can now be run locally and accessed through your browser. This is the preferred way to run Studio instead of using the Desktop App shown in the video. It is now called _LangSmith Studio_ instead of _LangGraph Studio_. Detailed setup instructions are available in the \"Getting Setup\" guide at the start of the course. You can find a description of Studio [here](https://docs.langchain.com/langsmith/studio), and specific details for local deployment [here](https://docs.langchain.com/langsmith/quick-start-studio#local-development-server).  \n",
    "To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- ðŸš€ API: http://127.0.0.1:2024\n",
    "- ðŸŽ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- ðŸ“š API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the **Studio UI** URL shown above.\n",
    "\n",
    "The LangGraph API  [supports editing graph state](https://docs.langchain.com/langsmith/add-human-in-the-loop). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's [stream `values`](https://docs.langchain.com/oss/python/langgraph/streaming#stream-graph-state), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '019a0358-31b4-7143-af47-2feeac0b27ce', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '9aaa247f-1e6e-4451-af25-ac678fe46d82'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '9aaa247f-1e6e-4451-af25-ac678fe46d82'}, {'content': '', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb3c3cb84d', 'id': 'chatcmpl-CSqw4HhOXHahA4tIr4mIdEhQB1QB4', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'lc_run--4a3794f6-52c3-41b5-9620-1710d6e8392d-0', 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_3sCWZZ89AoUe91MYc3ZBtJ0P', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '9aaa247f-1e6e-4451-af25-ac678fe46d82'}, {'content': '', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb3c3cb84d', 'id': 'chatcmpl-CSqw4HhOXHahA4tIr4mIdEhQB1QB4', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'lc_run--4a3794f6-52c3-41b5-9620-1710d6e8392d-0', 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_3sCWZZ89AoUe91MYc3ZBtJ0P', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'f05da6b3-27be-4896-967a-3ff60aa06d85', 'tool_call_id': 'call_3sCWZZ89AoUe91MYc3ZBtJ0P', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '9aaa247f-1e6e-4451-af25-ac678fe46d82'}, {'content': '', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb3c3cb84d', 'id': 'chatcmpl-CSqw4HhOXHahA4tIr4mIdEhQB1QB4', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'lc_run--4a3794f6-52c3-41b5-9620-1710d6e8392d-0', 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_3sCWZZ89AoUe91MYc3ZBtJ0P', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'f05da6b3-27be-4896-967a-3ff60aa06d85', 'tool_call_id': 'call_3sCWZZ89AoUe91MYc3ZBtJ0P', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 14, 'prompt_tokens': 159, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb3c3cb84d', 'id': 'chatcmpl-CSqw4xk8t3sPODL5beks5TlJBozgB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'lc_run--33a25ab0-f748-4c7f-a086-d9249e25fdc0-0', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 159, 'output_tokens': 14, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={} response_metadata={} id='c3ec872a-99a1-4eec-bcb6-a04973f48ac5'\n",
      "=========================\n",
      "content='' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f64f290af2', 'id': 'chatcmpl-CSqw6HYoyCI7z2AuKAAfSTQGbvzla', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--c91028e7-7a0a-4746-a4f5-edcff5380abc-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_AFChrxIQGbr7mmzr8buxymY0', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' name='multiply' id='f69a844b-5f82-4256-96dd-92b044e888d9' tool_call_id='call_AFChrxIQGbr7mmzr8buxymY0'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 159, 'output_tokens': 14, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 159, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb3c3cb84d', 'id': 'chatcmpl-CSqw7xBeinGuHlx0upkmo2tryppco', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--dba1c4af-ed8f-4fed-8770-2c3429603cd0-0'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can  [use `messages` mode](https://docs.langchain.com/oss/python/langgraph/streaming#supported-stream-modes) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "<!--You can dig further into the types [~here~](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages) [here](https://docs.langchain.com/oss/python/langgraph/concepts/langgraph_server). -->\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 019a0358-57dc-76f9-bc63-633eee467a86\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_mDtKBiuzkpN5ITWykhEFN0XU, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "--------------------------------------------------\n",
      "AI: The result\n",
      "--------------------------------------------------\n",
      "AI: The result of\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata and response_metadata.get(\"finish_reason\"):\n",
    "                    print(f\"Response Metadata: Finish Reason - {response_metadata['finish_reason']}\")                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dump-truck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
