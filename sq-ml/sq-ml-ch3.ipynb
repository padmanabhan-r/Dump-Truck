{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aea81338",
   "metadata": {},
   "source": [
    "# Chapter 3: Statistical Foundations\n",
    "\n",
    "This notebook covers the essential statistical concepts for machine learning:\n",
    "- **Histograms & Probability** - Understanding data distribution\n",
    "- **Discrete Distributions** - Binomial and Poisson\n",
    "- **Continuous Distributions** - Normal, Exponential, Uniform\n",
    "- **Models & Residuals** - Measuring prediction errors\n",
    "- **SSR, MSE, R²** - Quantifying model performance\n",
    "- **p-values** - Statistical significance\n",
    "\n",
    "Let's explore each concept with real examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507574da",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aecada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import binom, poisson, norm, expon, uniform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f70079",
   "metadata": {},
   "source": [
    "## 2. Histograms and Probability\n",
    "\n",
    "**The Problem**: Natural variation in data (you don't get the same number of french fries each time!)\n",
    "\n",
    "**Solution**: Use histograms to see patterns and calculate probabilities.\n",
    "\n",
    "**Formula**: $P(\\text{value in bin}) = \\frac{\\text{observations in bin}}{\\text{total observations}}$\n",
    "\n",
    "**Weaknesses**:\n",
    "- Sensitive to bin width (too wide = low precision, too narrow = gaps)\n",
    "- Cannot predict values in gaps where no data exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a0faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EXAMPLE: Number of French Fries in Each Order\\n\")\n",
    "\n",
    "# Simulate data: french fries count varies naturally\n",
    "np.random.seed(42)\n",
    "fries_data = np.random.normal(50, 5, 200).astype(int)\n",
    "\n",
    "print(f\"Collected {len(fries_data)} orders\")\n",
    "print(f\"Sample data: {fries_data[:10]}\\n\")\n",
    "\n",
    "# Create histogram\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Different bin widths\n",
    "bin_settings = [5, 10, 20]\n",
    "titles = ['Too Narrow (5 bins)', 'Just Right (10 bins)', 'Too Wide (20 bins)']\n",
    "\n",
    "for ax, bins, title in zip(axes, bin_settings, titles):\n",
    "    counts, edges, patches = ax.hist(fries_data, bins=bins, edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel('Number of Fries')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate probabilities\n",
    "print(\"CALCULATING PROBABILITY:\")\n",
    "print(f\"Total observations: {len(fries_data)}\\n\")\n",
    "\n",
    "# Probability of getting 45-50 fries\n",
    "count_45_50 = np.sum((fries_data >= 45) & (fries_data < 50))\n",
    "prob_45_50 = count_45_50 / len(fries_data)\n",
    "\n",
    "print(f\"Orders with 45-49 fries: {count_45_50}\")\n",
    "print(f\"Probability = {count_45_50}/{len(fries_data)} = {prob_45_50:.3f} or {prob_45_50*100:.1f}%\")\n",
    "\n",
    "# Probability of getting 50-55 fries\n",
    "count_50_55 = np.sum((fries_data >= 50) & (fries_data < 55))\n",
    "prob_50_55 = count_50_55 / len(fries_data)\n",
    "\n",
    "print(f\"\\nOrders with 50-54 fries: {count_50_55}\")\n",
    "print(f\"Probability = {count_50_55}/{len(fries_data)} = {prob_50_55:.3f} or {prob_50_55*100:.1f}%\")\n",
    "\n",
    "print(\"\\n⚠️  WEAKNESS: What if no one ordered exactly 60 fries? We have a gap!\")\n",
    "print(\"   Histogram can't predict probability for that gap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de924a",
   "metadata": {},
   "source": [
    "## 3. Discrete Probability Distributions\n",
    "\n",
    "**Solution to gaps**: Use mathematical distributions to approximate data!\n",
    "\n",
    "**Discrete Data**: Countable values only (Yes/No, 1, 2, 3)\n",
    "\n",
    "### 3.1 Binomial Distribution\n",
    "\n",
    "For **binary outcomes** (Heads/Tails, Yes/No, Success/Fail)\n",
    "\n",
    "**Formula**: $P(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}$\n",
    "\n",
    "Where:\n",
    "- $n$ = number of attempts/trials\n",
    "- $p$ = probability of success\n",
    "- $x$ = number of successes\n",
    "- $\\binom{n}{x}$ = combinations (all possible ways to get x successes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c83f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"BINOMIAL DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nEXAMPLE: Flipping a coin 10 times\")\n",
    "print(\"What's the probability of getting exactly 2 Heads?\\n\")\n",
    "\n",
    "# Parameters\n",
    "n = 10  # number of coin flips\n",
    "p = 0.5  # probability of heads\n",
    "x = 2   # we want exactly 2 heads\n",
    "\n",
    "# Calculate using binomial formula\n",
    "prob_2_heads = binom.pmf(x, n, p)\n",
    "\n",
    "print(f\"Parameters:\")\n",
    "print(f\"  n (trials) = {n}\")\n",
    "print(f\"  p (success probability) = {p}\")\n",
    "print(f\"  x (successes we want) = {x}\\n\")\n",
    "\n",
    "print(f\"P(X = 2) = {prob_2_heads:.4f} or {prob_2_heads*100:.2f}%\\n\")\n",
    "\n",
    "# Show full distribution\n",
    "x_values = range(0, n+1)\n",
    "probabilities = [binom.pmf(x, n, p) for x in x_values]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(x_values, probabilities, color='skyblue', edgecolor='black')\n",
    "plt.bar(2, prob_2_heads, color='red', edgecolor='black', label=f'P(X=2) = {prob_2_heads:.4f}')\n",
    "plt.xlabel('Number of Heads')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Binomial Distribution: 10 Coin Flips')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Real world example\n",
    "print(\"REAL-WORLD EXAMPLE: Customer Purchases\")\n",
    "print(\"30% of customers buy after seeing an ad\")\n",
    "print(\"We show ads to 20 customers\\n\")\n",
    "\n",
    "n_customers = 20\n",
    "p_buy = 0.3\n",
    "\n",
    "# What's probability exactly 5 buy?\n",
    "prob_5_buy = binom.pmf(5, n_customers, p_buy)\n",
    "print(f\"P(exactly 5 buy) = {prob_5_buy:.4f} or {prob_5_buy*100:.2f}%\")\n",
    "\n",
    "# What's probability 5 or more buy?\n",
    "prob_5_or_more = 1 - binom.cdf(4, n_customers, p_buy)\n",
    "print(f\"P(5 or more buy) = {prob_5_or_more:.4f} or {prob_5_or_more*100:.2f}%\\n\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "x_cust = range(0, n_customers+1)\n",
    "probs_cust = [binom.pmf(x, n_customers, p_buy) for x in x_cust]\n",
    "plt.bar(x_cust, probs_cust, color='lightcoral', edgecolor='black')\n",
    "plt.xlabel('Number of Customers Who Buy')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(f'Binomial: 20 Customers, p={p_buy}')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1433b25",
   "metadata": {},
   "source": [
    "### 3.2 Poisson Distribution\n",
    "\n",
    "For **counts over time/space** (pages read per hour, emails per day)\n",
    "\n",
    "**Formula**: $P(X = x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}$\n",
    "\n",
    "Where:\n",
    "- $\\lambda$ (lambda) = average rate\n",
    "- $x$ = number of events\n",
    "- $e$ = Euler's number (≈ 2.718)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"POISSON DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nEXAMPLE: Pages read per hour (average = 3 pages)\\n\")\n",
    "\n",
    "# Parameter\n",
    "lambda_rate = 3  # average pages per hour\n",
    "\n",
    "print(f\"λ (lambda) = {lambda_rate} pages/hour\\n\")\n",
    "\n",
    "# Calculate probabilities for different values\n",
    "x_pages = range(0, 10)\n",
    "probs_pages = [poisson.pmf(x, lambda_rate) for x in x_pages]\n",
    "\n",
    "# Specific examples\n",
    "prob_2_pages = poisson.pmf(2, lambda_rate)\n",
    "prob_5_pages = poisson.pmf(5, lambda_rate)\n",
    "\n",
    "print(f\"P(exactly 2 pages) = {prob_2_pages:.4f} or {prob_2_pages*100:.2f}%\")\n",
    "print(f\"P(exactly 5 pages) = {prob_5_pages:.4f} or {prob_5_pages*100:.2f}%\\n\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(x_pages, probs_pages, color='lightgreen', edgecolor='black')\n",
    "plt.xlabel('Number of Pages Read')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(f'Poisson Distribution (λ = {lambda_rate})')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Real world example\n",
    "print(\"REAL-WORLD EXAMPLE: Website Visits\")\n",
    "print(\"Average = 8 visits per minute\\n\")\n",
    "\n",
    "lambda_visits = 8\n",
    "x_visits = range(0, 20)\n",
    "probs_visits = [poisson.pmf(x, lambda_visits) for x in x_visits]\n",
    "\n",
    "prob_10_visits = poisson.pmf(10, lambda_visits)\n",
    "print(f\"P(exactly 10 visits) = {prob_10_visits:.4f} or {prob_10_visits*100:.2f}%\")\n",
    "\n",
    "# More than 12 visits\n",
    "prob_more_12 = 1 - poisson.cdf(12, lambda_visits)\n",
    "print(f\"P(more than 12 visits) = {prob_more_12:.4f} or {prob_more_12*100:.2f}%\\n\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(x_visits, probs_visits, color='orange', edgecolor='black')\n",
    "plt.xlabel('Number of Website Visits')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(f'Poisson: Website Visits (λ = {lambda_visits})')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Poisson is perfect for counting events over time/space!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090af475",
   "metadata": {},
   "source": [
    "## 4. Continuous Probability Distributions\n",
    "\n",
    "**Continuous Data**: Measurable with infinite precision (height, weight, time)\n",
    "\n",
    "### 4.1 Normal (Gaussian) Distribution - The Bell Curve\n",
    "\n",
    "**Formula**: $f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}$\n",
    "\n",
    "Where:\n",
    "- $\\mu$ (mu) = mean (center)\n",
    "- $\\sigma$ (sigma) = standard deviation (width)\n",
    "\n",
    "**CRITICAL CONCEPT**: \n",
    "- Y-axis = **Likelihood** (NOT probability!)\n",
    "- Probability = **Area Under the Curve** between two points\n",
    "- P(exact value) = 0 (a point has no width!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"NORMAL (GAUSSIAN) DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nEXAMPLE: Human Heights (cm)\\n\")\n",
    "\n",
    "# Parameters\n",
    "mu = 170  # mean height\n",
    "sigma = 10  # standard deviation\n",
    "\n",
    "print(f\"μ (mean) = {mu} cm\")\n",
    "print(f\"σ (standard deviation) = {sigma} cm\\n\")\n",
    "\n",
    "# Create x values\n",
    "x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\n",
    "y = norm.pdf(x, mu, sigma)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y, linewidth=2, color='blue')\n",
    "plt.fill_between(x, y, alpha=0.3, color='blue')\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Likelihood (NOT Probability!)')\n",
    "plt.title('Normal Distribution: Bell Curve')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(mu, color='red', linestyle='--', label=f'Mean = {mu}')\n",
    "plt.legend()\n",
    "\n",
    "print(\"⚠️  CRITICAL: Y-axis is LIKELIHOOD, not probability!\")\n",
    "print(\"    P(exactly 170.0000... cm) = 0 (infinite precision)\")\n",
    "print(\"    We calculate probability as AREA between two points:\\n\")\n",
    "\n",
    "# Calculate area under curve (probability)\n",
    "# P(165 < height < 175)\n",
    "prob_165_175 = norm.cdf(175, mu, sigma) - norm.cdf(165, mu, sigma)\n",
    "print(f\"P(165 < height < 175) = Area under curve\")\n",
    "print(f\"                      = {prob_165_175:.4f} or {prob_165_175*100:.2f}%\")\n",
    "\n",
    "# Visualize the area\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, y, linewidth=2, color='blue')\n",
    "x_fill = x[(x >= 165) & (x <= 175)]\n",
    "y_fill = norm.pdf(x_fill, mu, sigma)\n",
    "plt.fill_between(x_fill, y_fill, alpha=0.5, color='green', label=f'P(165<x<175)={prob_165_175:.3f}')\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Likelihood')\n",
    "plt.title('Probability = Area Under Curve')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(165, color='green', linestyle='--')\n",
    "plt.axvline(175, color='green', linestyle='--')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# More examples\n",
    "print(\"\\nMORE EXAMPLES:\")\n",
    "prob_160_180 = norm.cdf(180, mu, sigma) - norm.cdf(160, mu, sigma)\n",
    "print(f\"P(160 < height < 180) = {prob_160_180:.4f} or {prob_160_180*100:.2f}%\")\n",
    "\n",
    "prob_below_160 = norm.cdf(160, mu, sigma)\n",
    "print(f\"P(height < 160) = {prob_below_160:.4f} or {prob_below_160*100:.2f}%\")\n",
    "\n",
    "prob_above_180 = 1 - norm.cdf(180, mu, sigma)\n",
    "print(f\"P(height > 180) = {prob_above_180:.4f} or {prob_above_180*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b1a53",
   "metadata": {},
   "source": [
    "### 4.2 Other Continuous Distributions\n",
    "\n",
    "**Exponential**: Time between events  \n",
    "**Uniform**: Every value equally likely (random number generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# EXPONENTIAL DISTRIBUTION\n",
    "print(\"EXPONENTIAL DISTRIBUTION\")\n",
    "print(\"Use case: Time until next page turn\\n\")\n",
    "\n",
    "lambda_exp = 0.5  # rate parameter\n",
    "x_exp = np.linspace(0, 10, 1000)\n",
    "y_exp = expon.pdf(x_exp, scale=1/lambda_exp)\n",
    "\n",
    "axes[0].plot(x_exp, y_exp, linewidth=2, color='purple')\n",
    "axes[0].fill_between(x_exp, y_exp, alpha=0.3, color='purple')\n",
    "axes[0].set_xlabel('Time (minutes)')\n",
    "axes[0].set_ylabel('Likelihood')\n",
    "axes[0].set_title('Exponential Distribution\\nTime Between Events')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate probability\n",
    "prob_wait_2_4 = expon.cdf(4, scale=1/lambda_exp) - expon.cdf(2, scale=1/lambda_exp)\n",
    "print(f\"P(wait 2-4 minutes for next page) = {prob_wait_2_4:.4f} or {prob_wait_2_4*100:.2f}%\")\n",
    "\n",
    "# UNIFORM DISTRIBUTION\n",
    "print(\"\\nUNIFORM DISTRIBUTION\")\n",
    "print(\"Use case: Random number generation (1-10)\\n\")\n",
    "\n",
    "a, b = 1, 10  # range\n",
    "x_unif = np.linspace(a-1, b+1, 1000)\n",
    "y_unif = uniform.pdf(x_unif, a, b-a)\n",
    "\n",
    "axes[1].plot(x_unif, y_unif, linewidth=2, color='orange')\n",
    "axes[1].fill_between(x_unif, y_unif, alpha=0.3, color='orange')\n",
    "axes[1].set_xlabel('Value')\n",
    "axes[1].set_ylabel('Likelihood')\n",
    "axes[1].set_title('Uniform Distribution\\nEvery Value Equally Likely')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim(0, 0.15)\n",
    "\n",
    "# Calculate probability\n",
    "prob_3_7 = (7-3)/(b-a)  # For uniform: P = (width of interval) / (total range)\n",
    "print(f\"P(value between 3 and 7) = (7-3)/(10-1) = {prob_3_7:.4f} or {prob_3_7*100:.2f}%\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Different distributions for different data types!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8032c7",
   "metadata": {},
   "source": [
    "## 5. Models and Residuals\n",
    "\n",
    "**Model**: An approximation of reality (like a line) used to make predictions\n",
    "\n",
    "**Residual**: The vertical distance between observed and predicted values\n",
    "\n",
    "**Formula**: $\\text{Residual} = \\text{Observed} - \\text{Predicted}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e07b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MODELS AND RESIDUALS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nEXAMPLE: Predicting weight from height\\n\")\n",
    "\n",
    "# Create data\n",
    "np.random.seed(42)\n",
    "heights = np.array([150, 160, 165, 170, 175, 180, 185, 190])\n",
    "weights = heights * 0.5 + np.random.normal(0, 3, len(heights))\n",
    "\n",
    "# Fit a linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(heights.reshape(-1, 1), weights)\n",
    "\n",
    "# Make predictions\n",
    "predicted_weights = model.predict(heights.reshape(-1, 1))\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = weights - predicted_weights\n",
    "\n",
    "print(\"Data and Predictions:\")\n",
    "print(f\"{'Height':<10} {'Observed':<12} {'Predicted':<12} {'Residual':<10}\")\n",
    "print(\"-\" * 50)\n",
    "for h, obs, pred, res in zip(heights, weights, predicted_weights, residuals):\n",
    "    print(f\"{h:<10.1f} {obs:<12.2f} {pred:<12.2f} {res:<10.2f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left plot: Model with residuals\n",
    "axes[0].scatter(heights, weights, s=100, color='blue', alpha=0.6, label='Observed Data', zorder=3)\n",
    "axes[0].plot(heights, predicted_weights, color='red', linewidth=2, label='Model (Predictions)', zorder=2)\n",
    "\n",
    "# Draw residual lines\n",
    "for h, obs, pred in zip(heights, weights, predicted_weights):\n",
    "    axes[0].plot([h, h], [obs, pred], 'k--', alpha=0.5, linewidth=1)\n",
    "    axes[0].annotate('', xy=(h, pred), xytext=(h, obs),\n",
    "                    arrowprops=dict(arrowstyle='<->', color='green', lw=1.5))\n",
    "\n",
    "axes[0].set_xlabel('Height (cm)')\n",
    "axes[0].set_ylabel('Weight (kg)')\n",
    "axes[0].set_title('Model with Residuals\\n(Residual = Observed - Predicted)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right plot: Residuals\n",
    "axes[1].scatter(heights, residuals, s=100, color='green', alpha=0.6)\n",
    "axes[1].axhline(0, color='red', linestyle='--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Height (cm)')\n",
    "axes[1].set_ylabel('Residual (kg)')\n",
    "axes[1].set_title('Residual Plot\\n(Want residuals close to 0)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Residuals show prediction errors\")\n",
    "print(f\"   Positive residual: Model underestimated\")\n",
    "print(f\"   Negative residual: Model overestimated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f5c20",
   "metadata": {},
   "source": [
    "## 6. Measuring Goodness: SSR & MSE\n",
    "\n",
    "How do we quantify if a model is good?\n",
    "\n",
    "**Sum of Squared Residuals (SSR)**: $\\text{SSR} = \\sum_{i=1}^{n} (\\text{Observed}_i - \\text{Predicted}_i)^2$\n",
    "\n",
    "**Mean Squared Error (MSE)**: $\\text{MSE} = \\frac{\\text{SSR}}{n}$\n",
    "\n",
    "Why square? Makes all errors positive and penalizes large errors more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521fd4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SSR (Sum of Squared Residuals) & MSE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Using data from previous section\n",
    "print(\"\\nCalculating SSR and MSE:\\n\")\n",
    "\n",
    "print(f\"{'Height':<10} {'Observed':<12} {'Predicted':<12} {'Residual':<12} {'Residual²':<12}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "squared_residuals = []\n",
    "for h, obs, pred, res in zip(heights, weights, predicted_weights, residuals):\n",
    "    sq_res = res ** 2\n",
    "    squared_residuals.append(sq_res)\n",
    "    print(f\"{h:<10.1f} {obs:<12.2f} {pred:<12.2f} {res:<12.2f} {sq_res:<12.2f}\")\n",
    "\n",
    "# Calculate SSR\n",
    "SSR = np.sum(squared_residuals)\n",
    "print(f\"\\n{'='*65}\")\n",
    "print(f\"SSR (Sum of Squared Residuals) = {SSR:.2f}\")\n",
    "\n",
    "# Calculate MSE\n",
    "n = len(heights)\n",
    "MSE = SSR / n\n",
    "print(f\"MSE (Mean Squared Error) = SSR / n = {SSR:.2f} / {n} = {MSE:.2f}\")\n",
    "\n",
    "# Compare two models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARING TWO MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Model 2: Just predict the mean (simplest model)\n",
    "mean_weight = np.mean(weights)\n",
    "predicted_mean = np.full(len(weights), mean_weight)\n",
    "residuals_mean = weights - predicted_mean\n",
    "\n",
    "SSR_mean = np.sum(residuals_mean ** 2)\n",
    "MSE_mean = SSR_mean / n\n",
    "\n",
    "print(f\"\\nModel 1 (Fitted Line):\")\n",
    "print(f\"  SSR = {SSR:.2f}\")\n",
    "print(f\"  MSE = {MSE:.2f}\")\n",
    "\n",
    "print(f\"\\nModel 2 (Just predict mean = {mean_weight:.2f}):\")\n",
    "print(f\"  SSR = {SSR_mean:.2f}\")\n",
    "print(f\"  MSE = {MSE_mean:.2f}\")\n",
    "\n",
    "print(f\"\\n✅ Lower SSR/MSE = Better model!\")\n",
    "print(f\"   Model 1 wins! (SSR: {SSR:.2f} < {SSR_mean:.2f})\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Model 1\n",
    "axes[0].scatter(heights, weights, s=100, color='blue', alpha=0.6, label='Data', zorder=3)\n",
    "axes[0].plot(heights, predicted_weights, color='red', linewidth=2, label='Fitted Line', zorder=2)\n",
    "for h, obs, pred in zip(heights, weights, predicted_weights):\n",
    "    axes[0].plot([h, h], [obs, pred], 'g--', alpha=0.3, linewidth=1)\n",
    "axes[0].set_xlabel('Height (cm)')\n",
    "axes[0].set_ylabel('Weight (kg)')\n",
    "axes[0].set_title(f'Model 1: Fitted Line\\nSSR = {SSR:.2f}, MSE = {MSE:.2f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Model 2\n",
    "axes[1].scatter(heights, weights, s=100, color='blue', alpha=0.6, label='Data', zorder=3)\n",
    "axes[1].axhline(mean_weight, color='orange', linewidth=2, label='Mean', zorder=2)\n",
    "for h, obs in zip(heights, weights):\n",
    "    axes[1].plot([h, h], [obs, mean_weight], 'g--', alpha=0.3, linewidth=1)\n",
    "axes[1].set_xlabel('Height (cm)')\n",
    "axes[1].set_ylabel('Weight (kg)')\n",
    "axes[1].set_title(f'Model 2: Just the Mean\\nSSR = {SSR_mean:.2f}, MSE = {MSE_mean:.2f}')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c905c",
   "metadata": {},
   "source": [
    "## 7. R-Squared (R²) - The Universal Score\n",
    "\n",
    "**Problem**: SSR/MSE depend on units (meters vs millimeters)\n",
    "\n",
    "**Solution**: R² compares your model to the simplest model (the mean)\n",
    "\n",
    "**Formula**: $R^2 = \\frac{SSR_{mean} - SSR_{line}}{SSR_{mean}}$\n",
    "\n",
    "**Interpretation**:\n",
    "- **R² = 0**: Your model is no better than guessing the mean\n",
    "- **R² = 1**: Perfect predictions\n",
    "- **R² < 0**: Your model is worse than the mean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f9493",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"R-SQUARED (R²)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate R²\n",
    "print(f\"\\nUsing our model:\\n\")\n",
    "print(f\"SSR (fitted line) = {SSR:.2f}\")\n",
    "print(f\"SSR (mean) = {SSR_mean:.2f}\\n\")\n",
    "\n",
    "R_squared = (SSR_mean - SSR) / SSR_mean\n",
    "print(f\"R² = (SSR_mean - SSR_line) / SSR_mean\")\n",
    "print(f\"   = ({SSR_mean:.2f} - {SSR:.2f}) / {SSR_mean:.2f}\")\n",
    "print(f\"   = {R_squared:.4f}\\n\")\n",
    "\n",
    "print(f\"INTERPRETATION:\")\n",
    "print(f\"  R² = {R_squared:.4f} means our model explains {R_squared*100:.2f}% of the variation\")\n",
    "print(f\"  The remaining {(1-R_squared)*100:.2f}% is unexplained (noise)\\n\")\n",
    "\n",
    "# Test different scenarios\n",
    "print(\"=\"*60)\n",
    "print(\"DIFFERENT SCENARIOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Scenario 1: Good fit\n",
    "x1 = np.linspace(0, 10, 20)\n",
    "y1 = 2*x1 + 1 + np.random.normal(0, 1, 20)\n",
    "model1 = LinearRegression().fit(x1.reshape(-1, 1), y1)\n",
    "y1_pred = model1.predict(x1.reshape(-1, 1))\n",
    "r2_1 = 1 - (np.sum((y1 - y1_pred)**2) / np.sum((y1 - np.mean(y1))**2))\n",
    "\n",
    "axes[0].scatter(x1, y1, alpha=0.6, s=60)\n",
    "axes[0].plot(x1, y1_pred, 'r-', linewidth=2)\n",
    "axes[0].set_title(f'Good Fit\\nR² = {r2_1:.3f}')\n",
    "axes[0].set_xlabel('X')\n",
    "axes[0].set_ylabel('Y')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scenario 2: Bad fit (random data)\n",
    "x2 = np.linspace(0, 10, 20)\n",
    "y2 = np.random.normal(5, 2, 20)\n",
    "model2 = LinearRegression().fit(x2.reshape(-1, 1), y2)\n",
    "y2_pred = model2.predict(x2.reshape(-1, 1))\n",
    "r2_2 = 1 - (np.sum((y2 - y2_pred)**2) / np.sum((y2 - np.mean(y2))**2))\n",
    "\n",
    "axes[1].scatter(x2, y2, alpha=0.6, s=60, color='orange')\n",
    "axes[1].plot(x2, y2_pred, 'r-', linewidth=2)\n",
    "axes[1].axhline(np.mean(y2), color='green', linestyle='--', label='Mean')\n",
    "axes[1].set_title(f'Poor Fit (Random Data)\\nR² ≈ {r2_2:.3f} (close to 0)')\n",
    "axes[1].set_xlabel('X')\n",
    "axes[1].set_ylabel('Y')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "# Scenario 3: Negative R² (wrong model for data)\n",
    "x3 = np.linspace(0, 4*np.pi, 30)\n",
    "y3 = np.sin(x3) + np.random.normal(0, 0.1, 30)\n",
    "model3 = LinearRegression().fit(x3.reshape(-1, 1), y3)\n",
    "y3_pred = model3.predict(x3.reshape(-1, 1))\n",
    "r2_3 = 1 - (np.sum((y3 - y3_pred)**2) / np.sum((y3 - np.mean(y3))**2))\n",
    "\n",
    "axes[2].scatter(x3, y3, alpha=0.6, s=60, color='purple')\n",
    "axes[2].plot(x3, y3_pred, 'r-', linewidth=2, label='Linear (bad!)')\n",
    "axes[2].axhline(np.mean(y3), color='green', linestyle='--', label='Mean (better!)')\n",
    "axes[2].set_title(f'Wrong Model\\nR² = {r2_3:.3f} (negative!)')\n",
    "axes[2].set_xlabel('X')\n",
    "axes[2].set_ylabel('Y')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ R² SUMMARY:\")\n",
    "print(f\"   • R² = 1.0: Perfect fit\")\n",
    "print(f\"   • R² = 0.8-0.9: Very good fit\")\n",
    "print(f\"   • R² = 0.5-0.7: Moderate fit\")\n",
    "print(f\"   • R² ≈ 0: No better than mean\")\n",
    "print(f\"   • R² < 0: Worse than mean!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cdd879",
   "metadata": {},
   "source": [
    "## 8. p-values: Is the Difference Real or Random?\n",
    "\n",
    "**Goal**: Determine if a difference (Drug A vs Drug B) is real or just chance\n",
    "\n",
    "**Common threshold**: p < 0.05 (5%)\n",
    "\n",
    "**Interpretation**:\n",
    "- **p < 0.05**: Statistically significant (difference is likely real)\n",
    "- **p ≥ 0.05**: Not significant (could be random chance)\n",
    "\n",
    "**Warning**: \n",
    "- Small p-value ≠ large effect (can have tiny difference with huge data)\n",
    "- 5% threshold = 5% false positives are expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"p-VALUES: Statistical Significance\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Example: Drug trial\n",
    "print(\"\\nEXAMPLE: Testing a new drug\\n\")\n",
    "\n",
    "# Drug A results\n",
    "drug_a = np.array([120, 125, 118, 130, 122, 128, 124, 126, 119, 127])\n",
    "# Drug B results  \n",
    "drug_b = np.array([110, 115, 108, 112, 111, 114, 109, 113, 107, 116])\n",
    "\n",
    "print(f\"Drug A (n={len(drug_a)}): Recovery time = {np.mean(drug_a):.2f} days\")\n",
    "print(f\"Drug B (n={len(drug_b)}): Recovery time = {np.mean(drug_b):.2f} days\")\n",
    "print(f\"Difference: {np.mean(drug_a) - np.mean(drug_b):.2f} days\\n\")\n",
    "\n",
    "# Perform t-test\n",
    "from scipy.stats import ttest_ind\n",
    "t_stat, p_value = ttest_ind(drug_a, drug_b)\n",
    "\n",
    "print(f\"Statistical Test (t-test):\")\n",
    "print(f\"  t-statistic = {t_stat:.4f}\")\n",
    "print(f\"  p-value = {p_value:.4f}\\n\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(f\"✅ p < 0.05: STATISTICALLY SIGNIFICANT\")\n",
    "    print(f\"   The difference is likely REAL, not random chance!\")\n",
    "else:\n",
    "    print(f\"❌ p ≥ 0.05: NOT significant\")\n",
    "    print(f\"   Could be random chance.\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot\n",
    "axes[0].boxplot([drug_a, drug_b], labels=['Drug A', 'Drug B'])\n",
    "axes[0].set_ylabel('Recovery Time (days)')\n",
    "axes[0].set_title(f'Drug Comparison\\np-value = {p_value:.4f}')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Distribution\n",
    "axes[1].hist(drug_a, alpha=0.5, label=f'Drug A (mean={np.mean(drug_a):.1f})', bins=8, color='blue')\n",
    "axes[1].hist(drug_b, alpha=0.5, label=f'Drug B (mean={np.mean(drug_b):.1f})', bins=8, color='red')\n",
    "axes[1].axvline(np.mean(drug_a), color='blue', linestyle='--', linewidth=2)\n",
    "axes[1].axvline(np.mean(drug_b), color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Recovery Time (days)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution Comparison')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show false positive concept\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"UNDERSTANDING FALSE POSITIVES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nIf we use p < 0.05 threshold:\")\n",
    "print(f\"  • We accept 5% false positive rate\")\n",
    "print(f\"  • Out of 100 random tests, ~5 will show 'significant' by chance\")\n",
    "print(f\"  • This is why we need:\\n\")\n",
    "print(f\"    1. Multiple studies (replication)\")\n",
    "print(f\"    2. Effect size (is difference meaningful?)\")\n",
    "print(f\"    3. Proper experimental design\\n\")\n",
    "\n",
    "# Example: Small effect, large sample\n",
    "print(\"EXAMPLE: Small effect but large sample\\n\")\n",
    "\n",
    "np.random.seed(123)\n",
    "group1_large = np.random.normal(100, 10, 1000)  # 1000 samples\n",
    "group2_large = np.random.normal(100.5, 10, 1000)  # Tiny difference (0.5)\n",
    "\n",
    "t_stat_large, p_value_large = ttest_ind(group1_large, group2_large)\n",
    "\n",
    "print(f\"Group 1: mean = {np.mean(group1_large):.2f}\")\n",
    "print(f\"Group 2: mean = {np.mean(group2_large):.2f}\")\n",
    "print(f\"Difference: {np.mean(group2_large) - np.mean(group1_large):.2f} (very small!)\")\n",
    "print(f\"p-value = {p_value_large:.6f} (very small!)\\n\")\n",
    "\n",
    "print(f\"⚠️  LESSON:\")\n",
    "print(f\"   Small p-value (p={p_value_large:.6f}) confirms difference is REAL\")\n",
    "print(f\"   BUT difference is TINY (only 0.5 units)\")\n",
    "print(f\"   Statistical significance ≠ Practical importance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0056ff28",
   "metadata": {},
   "source": [
    "## 9. Chapter 3 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CHAPTER 3 SUMMARY: Statistical Foundations\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│ 1. HISTOGRAMS & PROBABILITY                                      │\n",
    "├──────────────────────────────────────────────────────────────────┤\n",
    "│ • Stack data into bins to see patterns                           │\n",
    "│ • P(bin) = observations in bin / total observations              │\n",
    "│ • Weakness: Sensitive to bin width, can't predict gaps           │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│ 2. DISCRETE DISTRIBUTIONS                                         │\n",
    "├──────────────────────────────────────────────────────────────────┤\n",
    "│ BINOMIAL: Binary outcomes (Yes/No, Heads/Tails)                  │\n",
    "│   Formula: P(X=x) = C(n,x) × p^x × (1-p)^(n-x)                   │\n",
    "│   Parameters: n (trials), p (success probability), x (successes) │\n",
    "│                                                                   │\n",
    "│ POISSON: Counts over time/space (pages/hour, emails/day)         │\n",
    "│   Formula: P(X=x) = (λ^x × e^(-λ)) / x!                          │\n",
    "│   Parameter: λ (lambda) = average rate                           │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│ 3. CONTINUOUS DISTRIBUTIONS                                       │\n",
    "├──────────────────────────────────────────────────────────────────┤\n",
    "│ NORMAL: Bell curve (height, test scores)                         │\n",
    "│   Parameters: μ (mean), σ (standard deviation)                   │\n",
    "│   Y-axis = LIKELIHOOD (not probability!)                         │\n",
    "│   Probability = Area under curve between two points              │\n",
    "│                                                                   │\n",
    "│ EXPONENTIAL: Time between events                                 │\n",
    "│ UNIFORM: All values equally likely (random numbers)              │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│ 4. MODELS & RESIDUALS                                             │\n",
    "├──────────────────────────────────────────────────────────────────┤\n",
    "│ Model: Approximation of reality (like a line)                    │\n",
    "│ Residual = Observed - Predicted                                  │\n",
    "│   • Positive residual: Model underestimated                      │\n",
    "│   • Negative residual: Model overestimated                       │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│ 5. MEASURING GOODNESS                                             │\n",
    "├──────────────────────────────────────────────────────────────────┤\n",
    "│ SSR (Sum of Squared Residuals):                                  │\n",
    "│   SSR = Σ(Observed - Predicted)²                                 │\n",
    "│   • Square to make positive                                      │\n",
    "│   • Penalizes large errors more                                  │\n",
    "│                                                                   │\n",
    "│ MSE (Mean Squared Error):                                        │\n",
    "│   MSE = SSR / n                                                  │\n",
    "│   • Average error                                                │\n",
    "│   • Allows comparison across datasets                            │\n",
    "│                                                                   │\n",
    "│ Lower SSR/MSE = Better model ✓                                   │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│ 6. R-SQUARED (R²)                                                 │\n",
    "├──────────────────────────────────────────────────────────────────┤\n",
    "│ Formula: R² = (SSR_mean - SSR_line) / SSR_mean                   │\n",
    "│                                                                   │\n",
    "│ Interpretation:                                                  │\n",
    "│   • R² = 1.0: Perfect predictions                                │\n",
    "│   • R² = 0.8-0.9: Very good                                      │\n",
    "│   • R² = 0.5-0.7: Moderate                                       │\n",
    "│   • R² ≈ 0: No better than mean                                  │\n",
    "│   • R² < 0: Worse than mean!                                     │\n",
    "│                                                                   │\n",
    "│ Benefit: Unit-independent (works across all scales)              │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│ 7. p-VALUES                                                       │\n",
    "├──────────────────────────────────────────────────────────────────┤\n",
    "│ Question: Is the difference real or random chance?               │\n",
    "│                                                                   │\n",
    "│ Threshold: p < 0.05 (5%)                                         │\n",
    "│   • p < 0.05: Statistically significant (likely real)            │\n",
    "│   • p ≥ 0.05: Not significant (could be chance)                  │\n",
    "│                                                                   │\n",
    "│ WARNINGS:                                                        │\n",
    "│   ⚠️  5% threshold = 5% false positives expected                 │\n",
    "│   ⚠️  Small p-value ≠ large effect                               │\n",
    "│   ⚠️  Can have tiny difference with huge sample → tiny p-value   │\n",
    "│   ⚠️  Statistical significance ≠ Practical importance            │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "✅ KEY TAKEAWAYS:\n",
    "   • Use distributions to model data (no more gaps!)\n",
    "   • Discrete: Binomial (binary), Poisson (counts)\n",
    "   • Continuous: Normal (bell curve), y-axis = likelihood\n",
    "   • Residuals measure prediction errors\n",
    "   • SSR/MSE quantify total error\n",
    "   • R² is universal score (0 to 1)\n",
    "   • p-values test if differences are real\n",
    "   • Always consider both statistical AND practical significance\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dump-truck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
